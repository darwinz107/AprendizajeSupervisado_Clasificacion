# -*- coding: utf-8 -*-
"""U3 S9 Taller 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q_nQc5NFX6IwtoRGfPs_OlDf6tA6s3XZ

Nombre: Darwin Alfredo Zambrano Muruzumbay

Curso: SOF-S-NO-9-5

Materia: Inteligencia artificial
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import drive
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, recall_score,precision_score,confusion_matrix, classification_report,roc_curve,auc

drive.mount("/content/drive")

df = pd.read_csv("/content/drive/MyDrive/SocialMediaEmotions/test.csv")
df.head()

df.info()

df.isnull().sum()

df.duplicated().sum()

df.columns.duplicated().sum()

df.drop_duplicates(inplace=True)

df.duplicated().sum()

for col in df.columns:
  print(f"{col}: {df[col].unique()}")

df['Age'] = pd.to_numeric(df['Age'],errors='coerce')
df['Age'] = df['Age'].fillna(0).astype('int64')
mediana = df['Age'][df['Age'] !=0].median()
df['Age'] = df['Age'].replace(0,mediana).astype('int64')

df['Messages_Sent_Per_Day'] = pd.to_numeric(df['Messages_Sent_Per_Day'],errors='coerce')
df['Messages_Sent_Per_Day'] = df['Messages_Sent_Per_Day'].fillna(0).astype('float64')

df.isnull().sum()

incorrectos = df[df['Gender'].isin(['Marie','27'])].index
df.drop(incorrectos,inplace=True)

df.info()

for col in df.columns:
  print(f'{col}: {df[col].unique()}')

df.drop('User_ID',axis=1,inplace=True)
df.head(10)

df.describe()

for col in df.select_dtypes(include=np.number).columns[:]:
  plt.figure()
  sns.histplot(df[col],bins=10)
  plt.title(f"Histograma de {col}")
  plt.show()

for col in df.select_dtypes(include='object').columns[:]:
  plt.figure()
  order = df[col].value_counts().index
  sns.countplot(x=col,data=df,order=order)
  plt.title(f"Grafica de barras de {col}")
  plt.xlabel(col)
  plt.ylabel("Count")
  plt.xticks(rotation=45,ha='right')
  plt.show()

for col in df.select_dtypes(include=np.number).columns:
  plt.figure()
  sns.boxplot(y=df[col])
  plt.title(f"Boxplot de {col}")
  plt.show()

Q1 = df.select_dtypes(include=np.number).quantile(0.25)
Q3 = df.select_dtypes(include= np.number).quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

for col in df.select_dtypes(include=np.number).columns[:]:
  df[col] = np.where(df[col] < lower_bound[col], lower_bound[col],df[col])
  df[col] = np.where(df[col] > upper_bound[col], upper_bound[col],df[col])

for col in df.select_dtypes(include=np.number).columns:
  plt.figure()
  sns.boxplot(y=df[col])
  plt.title(f"BoxPlot de {col}")
  plt.show()

"""# **Entrenamiento**"""

df.select_dtypes(include='object').columns

encoder_le = LabelEncoder()
df['Gender'] = encoder_le.fit_transform(df['Gender'])
print(df['Gender'].unique())
print(encoder_le.classes_)

df['Platform'] = encoder_le.fit_transform(df['Platform'])
print(df['Platform'].unique())
print(encoder_le.classes_)

df['Dominant_Emotion'] = encoder_le.fit_transform(df['Dominant_Emotion'])
print(df['Dominant_Emotion'].unique())
print(encoder_le.classes_)

x=df.iloc[:,:-1]
y=df['Dominant_Emotion']

plt.pie(df['Dominant_Emotion'].value_counts(),labels=df['Dominant_Emotion'].value_counts().index,autopct="%1.1f%%")
plt.title("Distribucion de Dominant_Emotion")
plt.show()

x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.7,random_state=42,stratify=y)

escaler = MinMaxScaler()
x_train[['Age', 'Daily_Usage_Time (minutes)', 'Posts_Per_Day',
       'Likes_Received_Per_Day', 'Comments_Received_Per_Day',
       'Messages_Sent_Per_Day']] = escaler.fit_transform(x_train[['Age', 'Daily_Usage_Time (minutes)', 'Posts_Per_Day',
       'Likes_Received_Per_Day', 'Comments_Received_Per_Day',
       'Messages_Sent_Per_Day']])

x_test[['Age', 'Daily_Usage_Time (minutes)', 'Posts_Per_Day',
       'Likes_Received_Per_Day', 'Comments_Received_Per_Day',
       'Messages_Sent_Per_Day']] = escaler.transform(x_test[['Age', 'Daily_Usage_Time (minutes)', 'Posts_Per_Day',
       'Likes_Received_Per_Day', 'Comments_Received_Per_Day',
       'Messages_Sent_Per_Day']])

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
x_train_resampled,y_train_resampled = smote.fit_resample(x_train,y_train)

plt.pie(y_train_resampled.value_counts(),labels=y_train_resampled.value_counts().index,autopct="%1.1f%%")
plt.title("Distribucion de la variable target")
plt.show()

"""# **Regresion logistica**"""

regresion_logistica = LogisticRegression(random_state=42,max_iter=2000)
regresion_logistica.fit(x_train_resampled,y_train_resampled)
y_pred = regresion_logistica.predict(x_test)
predicciones = pd.DataFrame({"y_test":y_test,"y_pred":y_pred})
predicciones

cm = confusion_matrix(y_test,y_pred)
plt.figure()
sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')
plt.title("Matriz de confusion")
plt.xlabel("Predicciones  - y_pred")
plt.ylabel("Valores reales - y_test")
plt.show()

print(classification_report(y_test,y_pred))
accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred,average="weighted")
recall = recall_score(y_test,y_pred, average=None,labels=[0,1,2,3,4,5])

print(f"accuracy: {accuracy *100:.2f}%")
print(f"precision: {precision*100:.2f}%")
print(f"recall: {recall}")

TPR = []
for i in range(len(cm)):
    TP = cm[i, i]
    FN = sum(cm[i, :]) - cm[i, i]
    TPR.append(TP / (TP + FN))

print(f'Sensibilidad (Tasa Verdaderos positivos) por clase: {TPR}')

TNR = []
for i in range(len(cm)):
    TN = sum(sum(cm)) - (sum(cm[i, :]) + sum(cm[:, i]) - cm[i, i])
    FP = sum(cm[:, i]) - cm[i, i]
    TNR.append(TN / (TN + FP))

print(f'Especificidad (Tasa Verdaderos negativos) por clase: {TNR}')

from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier

y_test_bin = label_binarize(y_test,classes=[0,1,2,4,5])
num_Classes = y_test_bin.shape[1]
num_Classes

classifier = OneVsRestClassifier(regresion_logistica)
y_score = classifier.fit(x_train_resampled,y_train_resampled).predict_proba(x_test)
y_score

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(num_Classes):
  fpr[i],tpr[i], _ = roc_curve(y_test_bin[:,i], y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])

plt.figure()
for i in range(num_Classes):
  plt.plot(fpr[i],tpr[i],label= f'Clase {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0,1],[0,1],'k--')
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.title("Grafica ROC AUC Multiclases")
plt.xlabel("Tasa de falsos positivos (fpr)")
plt.ylabel("Tasa de verdaderos positivos (tpr)")
plt.legend(loc="lower right")
plt.show()

roc_auc_weighted = auc(fpr[0], tpr[0]) * sum(y_test_bin[:,0]) + auc(fpr[1], tpr[1]) * sum(y_test_bin[:,1]) + auc(fpr[2], tpr[2]) * sum(y_test_bin[:,2])
roc_auc_weighted /= sum(sum(y_test_bin))
print(f"AUC ponderado promedio: {roc_auc_weighted:.2f}")

"""# **KNN**"""

from sklearn.neighbors import KNeighborsClassifier

model_knn = KNeighborsClassifier(n_neighbors=3)
model_knn.fit(x_train_resampled,y_train_resampled)
y_pred_knn = model_knn.predict(x_test)
predicciones_knn = pd.DataFrame({"y_test":y_test,"y_pred_knn":y_pred_knn})
predicciones_knn

cm = confusion_matrix(y_test,y_pred_knn)
plt.figure()
sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')
plt.title("Matriz de confusion")
plt.xlabel("Predicciones  - y_pred")
plt.ylabel("Valores reales - y_test")
plt.show()

print(classification_report(y_test,y_pred_knn))
accuracy = accuracy_score(y_test,y_pred_knn)
precision = precision_score(y_test,y_pred_knn,average="weighted")
recall = recall_score(y_test,y_pred_knn, average=None,labels=[0,1,2,3,4,5])

print(f"accuracy: {accuracy *100:.2f}%")
print(f"precision: {precision*100:.2f}%")
print(f"recall: {recall}")

TPR = []
for i in range(len(cm)):
    TP = cm[i, i]
    FN = sum(cm[i, :]) - cm[i, i]
    TPR.append(TP / (TP + FN))

print(f'Sensibilidad (Tasa Verdaderos positivos) por clase: {TPR}')

TNR = []
for i in range(len(cm)):
    TN = sum(sum(cm)) - (sum(cm[i, :]) + sum(cm[:, i]) - cm[i, i])
    FP = sum(cm[:, i]) - cm[i, i]
    TNR.append(TN / (TN + FP))

print(f'Especificidad (Tasa Verdaderos negativos) por clase: {TNR}')

from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier

y_test_bin = label_binarize(y_test,classes=[0,1,2,3,4,5])
num_Classes = y_test_bin.shape[1]
num_Classes

classifier = OneVsRestClassifier(model_knn)
y_score = classifier.fit(x_train_resampled,y_train_resampled).predict_proba(x_test)
y_score

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(num_Classes):
  fpr[i],tpr[i], _ = roc_curve(y_test_bin[:,i], y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])

plt.figure()
for i in range(num_Classes):
  plt.plot(fpr[i],tpr[i],label= f'Clase {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0,1],[0,1],'k--')
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.title("Grafica ROC AUC Multiclases")
plt.xlabel("Tasa de falsos positivos (fpr)")
plt.ylabel("Tasa de verdaderos positivos (tpr)")
plt.legend(loc="lower right")
plt.show()

roc_auc_weighted = auc(fpr[0], tpr[0]) * sum(y_test_bin[:,0]) + auc(fpr[1], tpr[1]) * sum(y_test_bin[:,1]) + auc(fpr[2], tpr[2]) * sum(y_test_bin[:,2])
roc_auc_weighted /= sum(sum(y_test_bin))
print(f"AUC ponderado promedio: {roc_auc_weighted:.2f}")

"""# **Naive Bayes**"""

from sklearn.naive_bayes import GaussianNB

model_nb = GaussianNB()
model_nb.fit(x_train_resampled,y_train_resampled)
y_pred_nb = model_nb.predict(x_test)
prediccionNB = pd.DataFrame({"y_test":y_test,"y_pred":y_pred_nb})
prediccionNB

cm = confusion_matrix(y_test,y_pred_nb)
plt.figure()
sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')
plt.title("Matriz de confusion")
plt.xlabel("Predicciones  - y_pred")
plt.ylabel("Valores reales - y_test")
plt.show()

print(classification_report(y_test,y_pred_nb))
accuracy = accuracy_score(y_test,y_pred_nb)
precision = precision_score(y_test,y_pred_nb,average="weighted")
recall = recall_score(y_test,y_pred_nb, average=None,labels=[0,1,2,3,4,5])

print(f"accuracy: {accuracy *100:.2f}%")
print(f"precision: {precision*100:.2f}%")
print(f"recall: {recall}")

TPR = []
for i in range(len(cm)):
    TP = cm[i, i]
    FN = sum(cm[i, :]) - cm[i, i]
    TPR.append(TP / (TP + FN))

print(f'Sensibilidad (Tasa Verdaderos positivos) por clase: {TPR}')

TNR = []
for i in range(len(cm)):
    TN = sum(sum(cm)) - (sum(cm[i, :]) + sum(cm[:, i]) - cm[i, i])
    FP = sum(cm[:, i]) - cm[i, i]
    TNR.append(TN / (TN + FP))

print(f'Especificidad (Tasa Verdaderos negativos) por clase: {TNR}')

from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier

y_test_bin = label_binarize(y_test,classes=[0,1,2,3,4,5])
num_Classes = y_test_bin.shape[1]
num_Classes

classifier = OneVsRestClassifier(model_nb)
y_score = classifier.fit(x_train_resampled,y_train_resampled).predict_proba(x_test)
y_score

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(num_Classes):
  fpr[i],tpr[i], _ = roc_curve(y_test_bin[:,i], y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])

plt.figure()
for i in range(num_Classes):
  plt.plot(fpr[i],tpr[i],label= f'Clase {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0,1],[0,1],'k--')
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.title("Grafica ROC AUC Multiclases")
plt.xlabel("Tasa de falsos positivos (fpr)")
plt.ylabel("Tasa de verdaderos positivos (tpr)")
plt.legend(loc="lower right")
plt.show()

roc_auc_weighted = auc(fpr[0], tpr[0]) * sum(y_test_bin[:,0]) + auc(fpr[1], tpr[1]) * sum(y_test_bin[:,1]) + auc(fpr[2], tpr[2]) * sum(y_test_bin[:,2])
roc_auc_weighted /= sum(sum(y_test_bin))
print(f"AUC ponderado promedio: {roc_auc_weighted:.2f}")

"""# **Arbol de decision**"""

from sklearn.tree import DecisionTreeClassifier
modelo_tree = DecisionTreeClassifier(random_state=42, max_depth=5, criterion = "gini")
modelo_tree.fit(x_train_resampled, y_train_resampled)
y_pred_tree = modelo_tree.predict(x_test)
prediccionArbol = pd.DataFrame({'y_test':y_test,'y_pred_tree':y_pred_tree})
prediccionArbol

cm = confusion_matrix(y_test,y_pred_tree)
plt.figure()
sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')
plt.title("Matriz de confusion")
plt.xlabel("Predicciones  - y_pred")
plt.ylabel("Valores reales - y_test")
plt.show()

print(classification_report(y_test,y_pred_tree))
accuracy = accuracy_score(y_test,y_pred_tree)
precision = precision_score(y_test,y_pred_tree,average="weighted")
recall = recall_score(y_test,y_pred_tree, average=None,labels=[0,1,2,3,4,5])

print(f"accuracy: {accuracy *100:.2f}%")
print(f"precision: {precision*100:.2f}%")
print(f"recall: {recall}")

TPR = []
for i in range(len(cm)):
    TP = cm[i, i]
    FN = sum(cm[i, :]) - cm[i, i]
    TPR.append(TP / (TP + FN))

print(f'Sensibilidad (Tasa Verdaderos positivos) por clase: {TPR}')

TNR = []
for i in range(len(cm)):
    TN = sum(sum(cm)) - (sum(cm[i, :]) + sum(cm[:, i]) - cm[i, i])
    FP = sum(cm[:, i]) - cm[i, i]
    TNR.append(TN / (TN + FP))

print(f'Especificidad (Tasa Verdaderos negativos) por clase: {TNR}')

from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier

y_test_bin = label_binarize(y_test,classes=[0,1,2,3,4,5])
num_Classes = y_test_bin.shape[1]
num_Classes

classifier = OneVsRestClassifier(modelo_tree)
y_score = classifier.fit(x_train_resampled,y_train_resampled).predict_proba(x_test)
y_score

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(num_Classes):
  fpr[i],tpr[i], _ = roc_curve(y_test_bin[:,i], y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])

plt.figure()
for i in range(num_Classes):
  plt.plot(fpr[i],tpr[i],label= f'Clase {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0,1],[0,1],'k--')
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.title("Grafica ROC AUC Multiclases")
plt.xlabel("Tasa de falsos positivos (fpr)")
plt.ylabel("Tasa de verdaderos positivos (tpr)")
plt.legend(loc="lower right")
plt.show()

roc_auc_weighted = auc(fpr[0], tpr[0]) * sum(y_test_bin[:,0]) + auc(fpr[1], tpr[1]) * sum(y_test_bin[:,1]) + auc(fpr[2], tpr[2]) * sum(y_test_bin[:,2])
roc_auc_weighted /= sum(sum(y_test_bin))
print(f"AUC ponderado promedio: {roc_auc_weighted:.2f}")

x_numeric = df.drop(columns=['Gender', 'Platform', 'Dominant_Emotion'])
x_numeric.columns